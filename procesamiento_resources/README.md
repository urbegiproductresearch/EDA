# ğŸ·ï¸ Procesamiento - Resources

Este mÃ³dulo procesa la tabla `resources` exportada desde la plataforma SaaS. Actualmente estÃ¡ adaptado a la comunidad piloto KonektaLan, con una estructura de supercategorÃ­as alineada con su modelo taxonÃ³mico.

El objetivo es transformar el CSV bruto en un dataset estructurado con supercategorÃ­as normalizadas, separaciÃ³n entre informaciÃ³n estructural y contextual, clasificaciÃ³n coherente por tipo de perfil y columnas organizadas de forma clara.

Estructura:

procesamiento_resources/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ resources_raw.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ resources_processed.csv
â”œâ”€â”€ src/
â”‚   â””â”€â”€ procesar_resources.py
â””â”€â”€ requirements.txt

Funcionamiento del script:

1. Carga y limpieza inicial. Se lee el CSV raw, se eliminan espacios en los nombres de columnas y se resuelven automÃ¡ticamente posibles duplicados estructurales.

2. ClasificaciÃ³n por supercategorÃ­as. El script analiza el campo â€œTipo de perfilâ€ y la columna â€œCategorÃ­asâ€ para generar las siguientes columnas estructuradas:

- supercategoria[GÃ©nero]
- supercategoria[Edad]
- supercategoria[Ãmbito]
- supercategoria[Rol]
- supercategoria[Sector]
- supercategoria[tipo_de_evento]
- supercategoria[tipo_de_contenido]
- supercategoria[Canales]

Estas columnas recogen Ãºnicamente valores estructurales definidos como vÃ¡lidos dentro del modelo taxonÃ³mico.

3. SeparaciÃ³n de informaciÃ³n contextual. Se generan columnas adicionales que almacenan informaciÃ³n no estructural:

- extra[info_noticia]
- extra[info_extra_cat_contenido]
- extra[categoria_contenido]

Estas columnas permiten mantener la taxonomÃ­a limpia sin perder informaciÃ³n contextual relevante. El script garantiza que todas las columnas que comienzan por `extra[` se sitÃºan al final del dataset final.

4. ExportaciÃ³n del archivo procesado en `data/processed/resources_processed.csv`.

LÃ³gica de clasificaciÃ³n:

- Para perfiles profesionales se identifican Rol, Sector, GÃ©nero y Edad.
- Para organizaciones se clasifica Ãmbito y Sector.
- Para noticias se identifica el tipo de contenido y se separa la informaciÃ³n contextual en `extra[info_noticia]`.
- Para eventos se clasifica el tipo de evento.
- Los canales se detectan en funciÃ³n del tipo de perfil y categorÃ­as asociadas.

AutomatizaciÃ³n:

El procesamiento se ejecuta automÃ¡ticamente mediante GitHub Actions cuando se sube un nuevo archivo raw a `procesamiento_resources/data/raw/`. El workflow instala dependencias, ejecuta el script, genera el CSV procesado y realiza commit automÃ¡tico si se detectan cambios.

El resultado final es un dataset estructurado, limpio y preparado para anÃ¡lisis segmentado, dashboards o explotaciÃ³n avanzada por comunidad.
